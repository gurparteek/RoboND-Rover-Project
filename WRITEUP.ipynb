{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Describe in your writeup (and identify where in your code) how you modified or added functions to add obstacle and rock sample identification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer 1: Under Color Thresholding, three new functions were added:\n",
    "#For identifying the navigable path:\n",
    "def find_nav_path(img, thresh=[160,160,160]):\n",
    "    # Create an array of zeros same xy size as img, but single channel\n",
    "    masked_img = np.zeros_like(img[:,:,0])\n",
    "    #Creating a mask for assigning 1 or True, to the pixels that satisfy all three thresholds.\n",
    "    #All three need to be true, so bitwise & for the single bit arrays.\n",
    "    mask = (img[:,:,0] > thresh[0]) & (img[:,:,1] > thresh[1]) & (img[:,:,2] > thresh[2])\n",
    "    #Item assignemt of True through masking to the pixels that satify the above condition.\n",
    "    masked_img[mask] = 1\n",
    "    # Return the binary image\n",
    "    return masked_img\n",
    "\n",
    "#In a similar fashion, create two more functions for identifying obstacles and the rocks.\n",
    "\n",
    "#Identifying the rocks.\n",
    "#R and G make yellow so low-cap the intensity for them at 115 and high-cap the intensity for B at 100.\n",
    "def find_rocks(img, thresh = [115,115,100]):\n",
    "    masked_img = np.zeros_like(img[:,:,0])\n",
    "    mask = (img[:,:,0] > thresh[0]) & (img[:,:,1] > thresh[1]) & (img[:,:,2] < thresh[2])\n",
    "    masked_img[mask] = 1\n",
    "    return masked_img\n",
    "\n",
    "#Identifying the obstacles.\n",
    "#Threshold of RGB < 160 reverses the threshold to find the obstacles.\n",
    "def find_obstacles(img, thresh = [150,150,150]):\n",
    "    masked_img = np.zeros_like(img[:,:,0])\n",
    "    mask = (img[:,:,0] < thresh[0]) & (img[:,:,1] < thresh[1]) & (img[:,:,2] < thresh[2])\n",
    "    masked_img[mask] = 1\n",
    "    return masked_img\n",
    "\n",
    "###NOTE###\n",
    "#In the simulation, a separate function was added to refine the result of the find_obstacles function as the 3 channel\n",
    "#image had black spots in it.\n",
    "def ref_find_obstacles(img):\n",
    "    nav_path = find_nav_path(img)\n",
    "    rocks = find_rocks(img)\n",
    "    obstacles = find_obstacles(img)\n",
    "    mask = (nav_path == 0) & (rocks == 0) & (obstacles == 0)\n",
    "    obstacles[mask] = 1\n",
    "    return obstacles\n",
    "#This Refines the find_obstacles function so that the black parts are replaced by the non-navigable parts,\n",
    "#not only in the displayed image but also in the world map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Describe in your writeup how you modified the process_image() to demonstrate your analysis and how you created a worldmap. Include your video output with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer2\n",
    "def process_image(img):\n",
    "    # 1) Defining the source and destination points for perspective transform\n",
    "    dst_size = 5 \n",
    "    bottom_offset = 6\n",
    "    source = np.float32([[14, 140], [301 ,140],[200, 96], [118, 96]])\n",
    "    destination = np.float32([[img.shape[1]/2 - dst_size, img.shape[0] - bottom_offset],\n",
    "                      [img.shape[1]/2 + dst_size, img.shape[0] - bottom_offset],\n",
    "                      [img.shape[1]/2 + dst_size, img.shape[0] - 2*dst_size - bottom_offset], \n",
    "                      [img.shape[1]/2 - dst_size, img.shape[0] - 2*dst_size - bottom_offset],\n",
    "                      ])\n",
    "    \n",
    "    # 2) Applying the perspective transform\n",
    "    warped = perspect_transform(img, source, destination)\n",
    "    \n",
    "    # 3) Applying the color threshold to identify navigable terrain/obstacles/rock samples\n",
    "    nav_path_img = find_nav_path(warped)\n",
    "    rocks_img = find_rocks(warped)\n",
    "    obstacles_img = find_obstacles(warped)\n",
    "    \n",
    "    # 4) Converting thresholded image pixel values to rover-centric coords\n",
    "    nav_x, nav_y = rover_coords(nav_path_img)\n",
    "    rock_x, rock_y = rover_coords(rocks_img)\n",
    "    obstacle_x, obstacle_y = rover_coords(obstacles_img)\n",
    "    \n",
    "    # 5) Converting rover-centric pixel values to world coords\n",
    "    xpos = data.xpos[data.count]\n",
    "    ypos = data.ypos[data.count]\n",
    "    yaw = data.yaw[data.count]\n",
    "    world_size = data.worldmap.shape[0]\n",
    "    scale = 10\n",
    "    \n",
    "    nav_x_world, nav_y_world = pix_to_world(nav_x, nav_y, xpos, ypos, yaw, world_size, scale)\n",
    "    rock_x_world, rock_y_world = pix_to_world(rock_x, rock_y, xpos, ypos, yaw, world_size, scale)\n",
    "    obstacle_x_world, obstacle_y_world = pix_to_world(obstacle_x, obstacle_y, xpos, ypos, yaw, world_size, scale)\n",
    "    \n",
    "    # 6) Updating the worldmap\n",
    "    data.worldmap[obstacle_y_world, obstacle_x_world, 0] += 1\n",
    "    data.worldmap[rock_y_world, rock_x_world, 1] += 1\n",
    "    data.worldmap[nav_y_world, nav_x_world, 2] += 1\n",
    "\n",
    "    # 7) Making the mosaic image\n",
    "    output_image = np.zeros((img.shape[0] + data.worldmap.shape[0], img.shape[1]*2, 3))\n",
    "    output_image[0:img.shape[0], 0:img.shape[1]] = img\n",
    "\n",
    "    warped = perspect_transform(img, source, destination)\n",
    "        # Add the warped image in the upper right hand corner\n",
    "    output_image[0:img.shape[0], img.shape[1]:] = warped\n",
    "\n",
    "        # Overlay worldmap with ground truth map\n",
    "    map_add = cv2.addWeighted(data.worldmap, 1, data.ground_truth, 0.5, 0)\n",
    "        # Flip map overlay so y-axis points upward and add to output_image \n",
    "    output_image[img.shape[0]:, 0:data.worldmap.shape[1]] = np.flipud(map_add)\n",
    "\n",
    "    cv2.putText(output_image,\"Populate this image with your analyses to make a video!\", (20, 20), \n",
    "                cv2.FONT_HERSHEY_COMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    data.count += 1 # Keep track of the index in the Databucket()\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "###NOTE: Output video in the output folder please."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. perception_step() and decision_step() functions have been filled in and their functionality explained in the writeup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer3\n",
    "\n",
    "#The working has been explained along side the code in comments.\n",
    "#To improve fidelity, I added a condition to add data to worldmap only when the roll and pitch are near zero in Step 7.\n",
    "def perception_step(Rover):\n",
    "    # Perform perception steps to update Rover()\n",
    "    # NOTE: camera image is coming to you in Rover.img\n",
    "    img = Rover.img\n",
    "\n",
    "    # 1) Define source and destination points for perspective transform\n",
    "    dst_size = 5 \n",
    "    bottom_offset = 6\n",
    "    source = np.float32([[14, 140], [301 ,140],[200, 96], [118, 96]])\n",
    "    destination = np.float32([[img.shape[1]/2 - dst_size, img.shape[0] - bottom_offset],\n",
    "                      [img.shape[1]/2 + dst_size, img.shape[0] - bottom_offset],\n",
    "                      [img.shape[1]/2 + dst_size, img.shape[0] - 2*dst_size - bottom_offset], \n",
    "                      [img.shape[1]/2 - dst_size, img.shape[0] - 2*dst_size - bottom_offset],\n",
    "                      ])\n",
    "    \n",
    "    # 2) Apply perspective transform\n",
    "    warped = perspect_transform(img, source, destination)\n",
    "    \n",
    "    # 3) Apply color threshold to identify navigable terrain/obstacles/rock samples\n",
    "    obstacles_img = ref_find_obstacles(warped)\n",
    "    rocks_img = find_rocks(warped)\n",
    "    nav_path_img = find_nav_path(warped)\n",
    "    \n",
    "    # 4) Update Rover.vision_image (this will be displayed on left side of screen)\n",
    "    Rover.vision_image[:,:,0] = obstacles_img*255\n",
    "    Rover.vision_image[:,:,1] = rocks_img*255\n",
    "    Rover.vision_image[:,:,2] = nav_path_img*255\n",
    "\n",
    "    # 5) Convert map image pixel values to rover-centric coords\n",
    "    obstacle_x, obstacle_y = rover_coords(obstacles_img)\n",
    "    rock_x, rock_y = rover_coords(rocks_img)\n",
    "    nav_x, nav_y = rover_coords(nav_path_img)\n",
    "\n",
    "    # 6) Convert rover-centric pixel values to world coordinates\n",
    "    xpos = Rover.pos[0]\n",
    "    ypos = Rover.pos[1]\n",
    "    yaw = Rover.yaw\n",
    "    world_size = Rover.worldmap.shape[0]\n",
    "    scale = 10\n",
    "\n",
    "    obstacle_x_world, obstacle_y_world = pix_to_world(obstacle_x, obstacle_y, xpos, ypos, yaw, world_size, scale)\n",
    "    rock_x_world, rock_y_world = pix_to_world(rock_x, rock_y, xpos, ypos, yaw, world_size, scale)\n",
    "    nav_x_world, nav_y_world = pix_to_world(nav_x, nav_y, xpos, ypos, yaw, world_size, scale)\n",
    "\n",
    "    # 7) Update Rover worldmap (to be displayed on right side of screen)\n",
    "    #Adding condition to add data to worldmap only when the roll and pitch are near zero.\n",
    "    if ((0 <= Rover.roll <= 1) or (359 <= Rover.roll <= 360)) and ((0 < Rover.pitch < 0.5) or (359.5 < Rover.pitch < 360)):\n",
    "        Rover.worldmap[obstacle_y_world, obstacle_x_world, 0] += 1\n",
    "        Rover.worldmap[rock_y_world, rock_x_world, 1] += 1\n",
    "        Rover.worldmap[nav_y_world, nav_x_world, 2] += 1\n",
    "\n",
    "    # 8) Convert rover-centric pixel positions to polar coordinates\n",
    "    # Update Rover pixel distances and angles\n",
    "    Rover.nav_dists, Rover.nav_angles = to_polar_coords(nav_x, nav_y)\n",
    "    \n",
    "    return Rover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###NOTE### For clarity, I created different functions for different states of throttle, steering, braking which are\n",
    "#documented in the decision.py file the full code for which I did not include here for brevity but the functions \n",
    "#themselves are in the code below.\n",
    "\n",
    "#I also made an unstuck() function that uses cycles as a factor for when to do the unstuck manuver which I have also\n",
    "#timed to last half a second. So when the Rover is not moving for 50 cycles but the throttle is there, it will turn\n",
    "#for half a second. It is shown in the decision.py file.\n",
    "\n",
    "#The working has been explained along side the code in comments.\n",
    "\n",
    "def decision_step(Rover):\n",
    "    global stuck_cycles\n",
    "    # Check if we have vision data to make decisions with\n",
    "    if Rover.nav_angles is not None:\n",
    "        # Check for Rover.mode status\n",
    "        if Rover.mode == 'forward': \n",
    "            # Check the extent of navigable terrain\n",
    "            if len(Rover.nav_angles) >= Rover.stop_forward:  \n",
    "                # If mode is forward, navigable terrain looks good \n",
    "                # and velocity is below max\n",
    "\n",
    "                if Rover.vel < Rover.max_vel:\n",
    "                    # Setting condition for when the Rover gets stuck.\n",
    "                    if -0.1 < Rover.vel < 0.1 and Rover.throttle == 0.2:\n",
    "                        #Doing the unstuck manuver.\n",
    "                        unstuck(Rover)\n",
    "\n",
    "                    # For setting the steer to zero when the rover is still in reverse.\n",
    "                    elif Rover.vel <= -0.1:\n",
    "                        # Restting stuck_cycle counter.\n",
    "                        stuck_cycles = 0\n",
    "                        no_steer_only_throttle(Rover)\n",
    "\n",
    "                    # If Rover.vel is between 0.1 and 1 which is Rover.max_vel.\n",
    "                    else:\n",
    "                        stuck_cycles = 0\n",
    "                        steer_and_throttle(Rover)\n",
    "\n",
    "                else: # Else coast when Rover.vel >= Rover.max_vel\n",
    "                    only_steer_no_throttle(Rover)\n",
    "\n",
    "            # If there's a lack of navigable terrain pixels then go to 'stop' mode\n",
    "            elif len(Rover.nav_angles) < Rover.stop_forward:\n",
    "                    # Set mode to \"stop\" and hit the brakes!\n",
    "                    brake(Rover)\n",
    "                    Rover.mode = 'stop'\n",
    "\n",
    "        # If we're already in \"stop\" mode then make different decisions\n",
    "        elif Rover.mode == 'stop':\n",
    "            # If we're in stop mode but still moving keep braking\n",
    "            if Rover.vel > 0.2:\n",
    "                brake(Rover)\n",
    "\n",
    "            # If we're not moving (vel < 0.2) then do something else\n",
    "            elif Rover.vel <= 0.2:\n",
    "                # Now we're stopped and we have vision data to see if there's a path forward\n",
    "                if len(Rover.nav_angles) < Rover.go_forward:\n",
    "                    # Turning to find a better path.\n",
    "                    turn(Rover,15)\n",
    "\n",
    "                # If we're stopped but see sufficient navigable terrain in front then go!\n",
    "                if len(Rover.nav_angles) >= Rover.go_forward:\n",
    "                    # Set throttle back to stored value, rel the brake and steer to mean angle.\n",
    "                    steer_and_throttle(Rover)\n",
    "                    Rover.mode = 'forward'\n",
    "    # Just to make the rover do something \n",
    "    # even if no modifications have been made to the code\n",
    "    else:\n",
    "        Rover.throttle = Rover.throttle_set\n",
    "        Rover.steer = 0\n",
    "        Rover.brake = 0  \n",
    "    # If in a state where want to pickup a rock send pickup command\n",
    "    if Rover.near_sample and Rover.vel == 0 and not Rover.picking_up:\n",
    "        Rover.send_pickup = True\n",
    "    return Rover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. By running drive_rover.pyand launching the simulator in autonomous mode, your rover does a reasonably good job at mapping the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer4:\n",
    "My configuration for the simulation was 1024X768 screen res, 'good' graphics quality, 'windowed' mode and 64-bit simulation. The FPS was mostly between 25 and 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "\n",
    "Add wall crawling:\n",
    "I attempted to add wall crawling but none of the runs were satisfactory. Some of the way I tried were:\n",
    "1. offsetting the mean angle but the problem with this is that one value of offset does not work for each situation.\n",
    "2. make a 'weighted offset' where the offset would increase with the navigable path ahead and to the sides but I could not make it to work perfectly in time.\n",
    "3. have separate mean angles for the negative and postive side and to favor one side that I want the wall to be on but no success.\n",
    "\n",
    "Pick up rocks:\n",
    "The Rover can be made to record separately, the location of the rocks and travel to them or just wall crawl really close and pick them up.\n",
    "\n",
    "Return:\n",
    "The starting postion can be assigned and then the Rover can travel back.\n",
    "\n",
    "Refining the thresholds:\n",
    "Thresholds such as the color thresholds, the thresholds to make the rover start and stop can be further refined."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
